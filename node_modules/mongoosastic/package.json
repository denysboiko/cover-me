{
  "author": {
    "name": "James R. Carr",
    "email": "james.r.carr@gmail.com",
    "url": "http://blog.james-carr.org"
  },
  "name": "mongoosastic",
  "description": "A mongoose plugin that indexes models into elastic search",
  "version": "0.2.6",
  "tags": [
    "mongodb",
    "elastic search",
    "mongoose",
    "full text search"
  ],
  "repository": {
    "type": "git",
    "url": "git://github.com/jamescarr/mongoosastic"
  },
  "main": "lib/mongoosastic.js",
  "dependencies": {
    "elastical": "0.0.12"
  },
  "peerDependencies": {
    "mongoose": "3.8.x"
  },
  "devDependencies": {
    "mocha": "*",
    "should": "*",
    "async": "*",
    "mongoose": "3.8.x"
  },
  "engines": {
    "node": ">= 0.8.0"
  },
  "scripts": {
    "test": "mocha -R spec -t 20000 -b"
  },
  "readme": "# Mongoosastic\n[![Build\nStatus](https://secure.travis-ci.org/jamescarr/mongoosastic.png?branch=master)](http://travis-ci.org/jamescarr/mongoosastic)\n\nA [mongoose](http://mongoosejs.com/) plugin that indexes models into [elasticsearch](http://www.elasticsearch.org/). I kept\nrunning into cases where I needed full text search capabilities in my\nmongodb based models only to discover mongodb has none. In addition to\nfull text search, I also needed the ability to filter ranges of data\npoints in the searches and even highlight matches. For these reasons,\nelastic search was a perfect fit and hence this project. \n\n## Current Version\nThe current version is ``0.2.3``\n\n## Installation\n\n```bash\nnpm install mongoosastic\n\n```\n\nOr add it to your package.json\n\n## Usage\n\nTo make a model indexed into elastic search simply add the plugin.\n\n\n```javascript\nvar mongoose     = require('mongoose')\n  , mongoosastic = require('mongoosastic')\n  , Schema       = mongoose.Schema\n\nvar User = new Schema({\n    name: String\n  , email: String\n  , city: String\n})\n\nUser.plugin(mongoosastic)\n```\n\nThis will by default simply use the pluralization of the model name as the index \nwhile using the model name itself as the type. So if you create a new\nUser object and save it, you can see it by navigating to\nhttp://localhost:9200/users/user/_search (this assumes elasticsearch is\nrunning locally on port 9200). \n\nThe default behavior is all fields get indexed into elasticsearch. This can be a little wasteful especially considering that\nthe document is now just being duplicated between mongodb and\nelasticsearch so you should consider opting to index only certain fields by specifying ''es_indexed'' on the \nfields you want to store:\n\n\n```javascript\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n})\n\nUser.plugin(mongoosastic)\n```\n\nIn this case only the name field\nwill be indexed for searching.\n\n####Indexing Nested Models\nIn order to index nested models you can refer following example.\n\n```javascript\nvar Comment = new Schema({\n    title: String\n  , body: String\n  , author: String\n})\n\n\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n  , comments: {type:[Comment], es_indexed:true}\n})\n\nUser.plugin(mongoosastic)\n```\n\nFinally, adding the plugin will add a new method to the model called\nsearch which can be used to make simple to complex searches. \n\n```javascript\n\nUser.search({query:\"john\"}, function(err, results) {\n  // results here\n});\n\n```\n\n### Indexing An Existing Collection\nAlready have a mongodb collection that you'd like to index using this\nplugin? No problem! Simply call the synchronize method on your model to\nopen a mongoose stream and start indexing documents individually. \n\n```javascript\nvar BookSchema = new Schema({\n  title: String\n});\nBookSchema.plugin(mongoosastic);\n\nvar Book = mongoose.model('Book', BookSchema)\n  , stream = Book.synchronize()\n  , count = 0;\n\nstream.on('data', function(err, doc){\n  count++;\n});\nstream.on('close', function(){\n  console.log('indexed ' + count + ' documents!');\n});\nstream.on('error', function(err){\n  console.log(err);\n});\n```\n\nYou can also synchronize a subset of documents based on a query!\n\n```javascript\nvar stream = Book.synchronize({author: 'Arthur C. Clarke'})\n```\n\nOne caveat... synchronization is kinda slow for now. Use with care.\n\n### Per Field Options\nSchemas can be configured to have special options per field. These match\nwith the existing [field mapping configurations](http://www.elasticsearch.org/guide/reference/mapping/core-types.html) defined by elasticsearch with the only difference being they are all prefixed by \"es_\". \n\nSo for example. If you wanted to index a book model and have the boost\nfor title set to 2.0 (giving it greater priority when searching) you'd\ndefine it as follows:\n\n```javascript\nvar BookSchema = new Schema({\n    title: {type:String, es_boost:2.0}\n  , author: {type:String, es_null_value:\"Unknown Author\"}\n  , publicationDate: {type:Date, es_type:'date'} \n}); \n\n```\nThis example uses a few other mapping fields... such as null_value and\ntype (which overrides whatever value the schema type is, useful if you\nwant stronger typing such as float).\n\n#### Creating Mappings for These Features\nThe way this can be mapped in elastic search is by creating a mapping\nfor the index the model belongs to. Currently to the best of my\nknowledge mappings are create once when creating an index and can only\nbe modified by destroying the index. \n\nAs such, creating the mapping is a one time operation and can be done as\nfollows (using the BookSchema as an example):\n\n```javascript \nvar BookSchema = new Schema({\n    title: {type:String, es_boost:2.0}\n  , author: {type:String, es_null_value:\"Unknown Author\"}\n  , publicationDate: {type:Date, es_type:'date'} \n\nBookSchema.plugin(mongoosastic);\nvar Book = mongoose.model('Book', BookSchema);\nBook.createMapping(function(err, mapping){\n  // do neat things here\n});\n\n```\nThis feature is still a work in progress. As of this writing you'll have\nto manage whether or not you need to create the mapping, mongoosastic\nwill make no assumptions and simply attempt to create the mapping. If\nthe mapping already exists, an Exception detailing such will be\npopulated in the `err` argument. \n\n#### Mapping options\nThere are various types that can be defined in elasticsearch. Check out http://www.elasticsearch.org/guide/reference/mapping/ for more information. Here are examples to the currently possible definitions in mongoosastic:\n\n```javascript\nvar ExampleSchema = new Schema({\n  // String (core type)\n  string: {type:String, es_boost:2.0},\n\n  // Number (core type)\n  number: {type:Number, es_type:'integer'},\n\n  // Date (core type)\n  date: {type:Date, es_type:'date'},\n\n  // Array type\n  array: {type:Array, es_type:'string'},\n\n  // Object type \n  object: {\n    field1: {type: String},\n    field2: {type: String}\n  },\n\n  // Nested type \n  nested: [SubSchema],\n\n  // Multi field type\n  multi_field: {\n    type: String,\n    es_type: 'multi_field',\n    es_fields: {\n      multi_field: { type: 'string', index: 'analyzed' },\n      untouched: { type: 'string', index: 'not_analyzed' }\n    }\n  },\n\n  // Geo point type\n  geo: {\n    type: String,\n    es_type: 'geo_point'\n  },\n\n  // Geo point type with lat_lon fields\n  geo_with_lat_lon: {\n    geo_point: {\n      type: String,\n      es_type: 'geo_point',\n      es_lat_lon: true\n    },\n    lat: { type: Number },\n    lon: { type: Number }\n  }\n});\n\n// Used as nested schema above.\nvar SubSchema = new Schema({\n  field1: {type: String},\n  field2: {type: String}\n});\n```\n\n### Advanced Queries\nThe full query DSL of elasticsearch is exposed through the search\nmethod. For example, if you wanted to find all people between ages 21\nand 30:\n\n```javascript\nPerson.search({\n  query:{\n    range: {\n      age:{\n        from:21\n      , to: 30\n      }\n    }\n  }\n}, function(err, people){\n   // all the people who fit the age group are here!   \n});\n\n```\n\nSee the elasticsearch [Query DSL](http://www.elasticsearch.org/guide/reference/query-dsl/) docs for more information.\n\n### Hydration\nBy default objects returned from performing a search will be the objects\nas is in elastic search. This is useful in cases where only what was\nindexed needs to be displayed (think a list of results) while the actual\nmongoose object contains the full data when viewing one of the results.\n\nHowever, if you want the results to be actual mongoose objects you can\nprovide {hydrate:true} as the second argument to a search call.\n\n```javascript\n\nUser.search({query:\"john\"}, {hydrate:true}, function(err, results) {\n  // results here\n});\n\n```\n\nYou can also pass in a `hydrateOptions` object with information on\nhow to query for the mongoose object.\n\n```javascript\n\nUser.search({query:\"john\"}, {hydrate:true, hydrateOptions: {select: 'name age'}}, function(err, results) {\n  // results here\n});\n\n```\n\nNote using hydrate will be a degree slower as it will perform an elasticsearch\nquery and then do a query against mongodb for all the ids returned from\nthe search result. \n\nYou can also default this to always be the case by providing it as a\nplugin option (as well as setting default hydrate options):\n\n\n```javascript\nvar User = new Schema({\n    name: {type:String, es_indexed:true}\n  , email: String\n  , city: String\n})\n\nUser.plugin(mongoosastic, {hydrate:true, hydrateOptions: {lean: true}})\n```\n\n\n### Indexing On Demand\nWhile developing mongoose I came across a scenario where we needed to be\nable to save models (and search them) but a single action would\n\"publish\" those models to be searched from a public site. To address\nthis I create a new method: `index`.\n\n#### Usage\nUsage is as simple as calling index on an existing model.\n\n```javascript\nDude.findOne({name:'Jeffery Lebowski', function(err, dude){\n  dude.awesome = true;\n  dude.index(function(err, res){\n    console.log(\"egads! I've been indexed!\");\n  });\n});\n```\n\nThe index method takes 3 arguments:\n\n* `index` (optional) - the index to publish to. Defaults to the index\n  the model was setup with.\n* `type` (optional) - the type to publish as. Defaults to the type the\n  model was setup with.\n* `callback` - callback function to be invoked when model has been\n  indexed.\n\nNote that indexing a model does not mean it will be persisted to\nmongodb. Use save for that.\n\n### Model.plugin(mongoosastic, options)\n\nOptions are:\n\n* `index` - the index in elastic search to use. Defaults to the\n  pluralization of the model name.\n* `type`  - the type this model represents in elastic search. Defaults\n  to the model name.\n* `host` - the host elastic search is running on\n* `port` - the port elastic search is running on\n* `hydrate` - whether or not to lookup results in mongodb before\n  returning results from a search. Defaults to false.\n\nExperimental Options:\n* `useRiver` - true for use streaming and other capabilities\n\n#### Specifying Different Index and Type\nPerhaps you have an existing index and you want to specify the index and\ntype used to index your document? No problem!!\n\n```javascript\nvar SupervisorSchema = new Schema({\n  name: String\n, department: String\n});\n\nSupervisorSchema.plugin(mongoosastic, {index: 'employees', type:'manager'});\n\nvar Supervisor = mongoose.model('supervisor', SupervisorSchema);\n\n```\n### To Use the River Option (EXPERIMENTAL)\n\nThe Elasticsearch MongoDB River functionality if very new and very beta. The latest it has been tested against is as follows:\n\n  - MongoDB v2.4.1\n  - Elasticsearch v0.20.6\n  - elasticsearch-river-mongodb v1.6.5\n\nThe above configuration has exhibited the most stability.\n\n#### Setup\nMongodb must be running with [replica sets](http://docs.mongodb.org/manual/tutorial/deploy-replica-set/).\n\nInstall the [elasticsearch-river-mongodb plugin](https://github.com/richardwilly98/elasticsearch-river-mongodb)\n\nAdvanced Configurations\n\n```javascript\nvar options = {\n  useRiver: {   \n    gridfs: false/true \n  }\n}\n```\nto create your River only call\n```javascript\nYourModel.river(function() {})\n```\n\n#### Testing\n\nBy default river tests do not run as it can be difficult to setup. If you wish to run river tests set the environment variable `MONGOOSASTIC_RIVER=true`\n\n## Contributing\nPull requests are always welcome as long as an accompanying test case is\nassociated. \n\nThis project is configured to use [git\nflow](https://github.com/nvie/gitflow/) and the following conventions\nare used:\n\n* ``develop`` - represents current active development and can possibly be\n  unstable. \n* ``master`` - pristine copy of repository, represents the currently\n  stable release found in the npm index.\n* ``feature/**`` - represents a new feature being worked on\n\nIf you wish to contribute, the only requirement is to: \n\n- branch a new feature branch from develop (if you're working on an\n  issue, prefix it with the issue number)\n- make the changes, with accompanying test cases\n- issue a pull request against develop branch\n\nAlthough I use git flow and prefix feature branches with \"feature/\" I\ndon't require this for pull requests... all I care is that the feature\nbranch name makes sense. \n\nPulls requests against master or pull requests branched from master will\nbe rejected.\n\n#### Examples\nSomeone picks up issue #39 on selective indexing.\n\nGood branch names:\n* 39-selective-indexing\n* feature/39-selective-indexing\n\nSomeone submits a new feature that allows shard configuration:\n\nGood branch names:\n* feature/shard-configuration\n* shard-configuration\n* or file an issue, then create a feature branch\n\nFeel free to ping me if you need help! :)\n\n### Running Tests\nIn order to run the tests you will need:\n\n* An elasticsearch server running on port 9200\n* A mongodb server\n* [mocha](http://visionmedia.github.com/mocha/)\n\nWith those installed, running ''npm test'' will run the tests with the\npreferred timeout (which is extended for integration tests. \n\n\n## License\nCopyright (c) 2012 James R. Carr <james.r.carr@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n",
  "readmeFilename": "readme.md",
  "bugs": {
    "url": "https://github.com/jamescarr/mongoosastic/issues"
  },
  "homepage": "https://github.com/jamescarr/mongoosastic",
  "_id": "mongoosastic@0.2.6",
  "dist": {
    "shasum": "4481816b01770552f10fcc15f848a034762291e4",
    "tarball": "http://registry.npmjs.org/mongoosastic/-/mongoosastic-0.2.6.tgz"
  },
  "_from": "mongoosastic@*",
  "_npmVersion": "1.3.14",
  "_npmUser": {
    "name": "taterbase",
    "email": "taterbase@gmail.com"
  },
  "maintainers": [
    {
      "name": "jamescarr",
      "email": "james.r.carr@gmail.com"
    },
    {
      "name": "taterbase",
      "email": "shankga@gmail.com"
    }
  ],
  "directories": {},
  "_shasum": "4481816b01770552f10fcc15f848a034762291e4",
  "_resolved": "https://registry.npmjs.org/mongoosastic/-/mongoosastic-0.2.6.tgz"
}
